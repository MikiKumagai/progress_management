task_id,word,meaning,word_learned_at,meaning_learned_at
3,AI効果,AIは知能をもっていないと考えてしまう心理,1,1,2025-08-01,2025-08-01
3,エニアック,1946年ペンシルベニア大で開発、汎用電子式デジタルコンピュータ、大砲の弾道計算,1,1,2025-08-01,2025-08-01
3,ダートマス会議,「人工知能に関する〇〇大学の夏期研究会」機械が人間の知能のように振る舞う方法,1,1,2025-08-01,2025-08-01
3,第1次AIブーム,1950年代後半～1960年代、推論や探索の研究が盛んに。トイ・プロブレムで終焉,1,1,2025-08-01,2025-08-01
3,第2次AIブーム,1980年代、エキスパートシステムにより、複雑な課題に対応。知識量の限界で終焉,1,1,2025-08-01,2025-08-01
3,第3次AIブーム,2000年代～現在、ビッグデータを用いて機械学習が実用化、ディープラーニングの登場,1,1,2025-08-01,2025-08-01
3,トイ・プロブレム,迷路や数学の定理の証明のような簡単な問題,1,1,2025-08-01,2025-08-01
3,エキスパートシステム,特定の専門分野の知識をコンピュータに取り込み、推論や判断ができるようにした,1,1,2025-08-01,2025-08-01
3,第五世代コンピュータ,自然言語処理等が目標、第2次AIブームでの日本の取り組み。頓挫。,1,1,2025-08-01,2025-08-01
3,ビッグデータ,予測に使う大量のデータ。構造化されていないrawデータの状態で保存される。,1,1,2025-08-01,2025-08-01
3,フレーム問題,AIは現実世界の複雑な状況を正確に表現し、適切な推論を行うことができない。,1,1,2025-08-01,2025-08-01
3,チューリングテスト,AIが人間のように知的に振る舞えるかどうかを判定するためのテスト,1,1,2025-08-01,2025-08-01
3,イライザ,初期の対話型人工知能プログラム,1,1,2025-08-01,2025-08-01
3,シンボルグラウンディング問題,AIは物事や文脈の本質を読み取れないという問題。考える、でなく知ってる。,1,1,2025-08-01,2025-08-01
3,機械翻訳,言語をコンピュータを用いて変換する技術,1,1,2025-08-01,2025-08-01
3,ルールベース機械翻訳,機械翻訳。人間が作成した言語ルールと辞書データを基に生成。直訳,1,1,2025-08-01,2025-08-01
3,統計的機械翻訳,機械翻訳。フレーズ単位での翻訳と並び替えを組み合わせた手法,1,1,2025-08-01,2025-08-01
3,ニューラル機械翻訳,機械翻訳。文全体を文脈として捉え、自然な語順を生成し、より流暢な訳文を生成,1,1,2025-08-01,2025-08-01
3,探索木,特定の値を高速に探し出すことができるようにした木構造。選択肢によって分かれる,1,1,2025-08-01,2025-08-01
3,幅優先探索,出発点に近い点から順に探索する,1,1,2025-08-01,2025-08-01
3,深さ優先探索,とにかく行けるとこまで行ってそれ以上進めなくなったら一歩戻ってそこから探索する,1,1,2025-08-01,2025-08-01
3,リッジ回帰,L2正則化。過学習を防ぐ。重みをできるだけ小さくする。,1,1,2025-08-01,2025-08-01
3,モンテカルロ法,確率的なイベントや計算が難しい場合に、ランダムな値で試行と評価を繰り返し解を求める方法,1,1,2025-08-01,2025-08-01
3,MYCIN,1970 年代、エキスパートシステムの一種。医療診断に使われる,1,1,2025-08-01,2025-08-01
3,プレイアウト,乱数を用いて、終局までプレイすること、モンテカルロ法によるゲームの戦法,1,1,2025-08-01,2025-08-01
3,意味ネットワーク,意味記憶の構造を表すためのモデル。単語や概念同士の関係性をグラフによって表したもの,1,1,2025-08-01,2025-08-01
3,IBM,主にハードウェア、ソフトウェア、コンサルティング、ITサービスを提供する有名なIT企業,1,1,2025-08-01,2025-08-01
3,ワトソン,2006年、IBMが開発したAI（人工知能）システム、質問応答や意思決定支援などの機能,1,1,2025-08-01,2025-08-01
3,東ロボくん,2011年から実施したプロジェクト「ロボットは東大に入れるか」で開発された人工知能,1,1,2025-08-01,2025-08-01
3,スパムフィルタ,メールが迷惑メールかどうか判断する機械学習によるアプリケーション,1,1,2025-08-01,2025-08-01
3,ILSVRC,画像認識を競うコンペ,1,1,2025-08-01,2025-08-01
3,GPT,OpenAIによって開発、自然言語処理モデル、人間のように自然な文章を生成,1,1,2025-08-01,2025-08-01
3,回帰問題,出力値が数値になるような問題,1,1,2025-08-01,2025-08-01
3,分類問題,出力値がいずれかのクラスになるような問題,1,1,2025-08-01,2025-08-01
3,教師なし学習,答えが無いデータで、データの傾向を使って予測モデルを作成する学習,1,1,2025-08-01,2025-08-01
3,線形回帰,真っすぐの線のモデル,1,1,2025-08-01,2025-08-01
3,ラッソ回帰,L1正則化。過学習を防ぐ。最小二乗法の係数（傾き）をできるだけ小さくするためにいくつかの特徴量を無視する,1,1,2025-08-01,2025-08-01
3,AdaBoost,決定木のアンサンブル学習。ブースティング。間違えたデータに重みを置くことで、次のモデルがそのデータに注目,1,1,2025-08-01,2025-08-01
3,カーネル関数,今の次元では分けられないデータを、そのままの状態で高次元として計算できるようにする関数。,1,1,2025-08-01,2025-08-01
3,ロジスティック回帰,シグモイド関数によって得られるモデル,1,1,2025-08-01,2025-08-01
3,シグモイド関数,０〜１のS字曲線を導き出す関数,1,1,2025-08-01,2025-08-01
3,正例,正に分類される事例、陽性、TRUE,1,1,2025-08-01,2025-08-01
3,負例,負に分類される事例、陰性、FALSE,1,1,2025-08-01,2025-08-01
3,ソフトマックス関数,出力の合計が１になる関数,1,1,2025-08-01,2025-08-01
3,2クラス分類問題,出力値が論理値になるような分類問題,1,1,2025-08-01,2025-08-01
3,多クラス分類問題,出力値が3つ以上のクラスのいずれかになるような分類問題,1,1,2025-08-01,2025-08-01
3,ランダムフォレスト,決定木のアンサンブル学習。バギング。多数決で組み合わせる。,1,1,2025-08-01,2025-08-01
3,決定木,教師あり学習、木構造を使ってデータを分析する手法、割合で確率を求める,1,1,2025-08-01,2025-08-01
3,ブートストラップサンプリング,同じデータが何回も採用されることを許容すること,1,1,2025-08-01,2025-08-01
3,アンサンブル学習,より精度の高い予測を得るために2つ以上の学習モデルを組み合わせたもの,1,1,2025-08-01,2025-08-01
3,バギング,アンサンブル学習のひとつ。並列,1,1,2025-08-01,2025-08-01
3,ブースティング,アンサンブル学習のひとつ。直列,1,1,2025-08-01,2025-08-01
3,単回帰分析,1つの説明変数と1つの目的変数の間の関係をモデル化する回帰分析手法,1,1,2025-08-01,2025-08-01
3,カーネルトリック,SVMで使われる、計算コストを下げるテクニック。高次元化せずに計算できる。,1,1,2025-08-01,2025-08-01
3,XGBoost,勾配ブースティングの改良版。過学習しにくい,1,1,2025-08-01,2025-08-01
3,サポートベクターマシン,教師あり学習を用いてデータを分割する境界線（超平面）を見つけるアルゴリズム,1,1,2025-08-01,2025-08-01
3,SVM,サポートベクターマシンのこと,1,1,2025-08-01,2025-08-01
3,重回帰分析,1つの結果（目的変数）を説明するために、複数の要因（説明変数）がどのように影響を与えているかを分析する統計的手法,1,1,2025-08-01,2025-08-01
3,教師あり学習,特徴量とターゲットの値がセットになっているデータで学習する,1,1,2025-08-01,2025-08-01
3,時系列分析,時間の経過とともに変化するデータを分析し、将来を予測する手法,1,1,2025-08-01,2025-08-01
3,時系列データ,時間の経過とともに測定されたデータ,1,1,2025-08-01,2025-08-01
3,階層なしクラスタリング,主にKmeans、DBSCAN、OPTICSなど。データが自然な階層構造を持たない場合に使う,1,1,2025-08-01,2025-08-01
3,k-means法,クラスタリングの手法、重心を探す,1,1,2025-08-01,2025-08-01
3,クラスタ,データを特徴ごとに分類する手法,1,1,2025-08-01,2025-08-01
3,階層ありクラスタリング,データの集合を似ているもの同士でクラスタにまとめていく手法,1,1,2025-08-01,2025-08-01
3,勾配ブースティング,決定木のアンサンブル学習。ブースティング。勾配降下法で次のモデルを更新,1,1,2025-08-01,2025-08-01
3,交差検証,訓練データとテストデータに分割・評価を複数回繰り返す手法,1,1,2025-08-01,2025-08-01
3,主成分分析,次元削減の手法のひとつ。分散が最大となる方向を見つけ出し、それを新たな軸としてデータを変換,1,1,2025-08-01,2025-08-01
3,PCA,主成分分析のこと,1,1,2025-08-01,2025-08-01
3,デンドログラム,階層型クラスタリングの結果を木状に可視化した図,1,1,2025-08-01,2025-08-01
3,訓練データ,モデルを作成するための訓練用データ,1,1,2025-08-01,2025-08-01
3,テストデータ,モデルを評価するためのデータ,1,1,2025-08-01,2025-08-01
3,k-分割交差検証,訓練データとテストデータにk回分割（サブセット）してk回評価する手法,1,1,2025-08-01,2025-08-01
3,検証データ,重みとか以外のハイパーパラメータをチューニングするのに使う。訓練データから分岐,1,1,2025-08-01,2025-08-01
3,平均二乗誤差,誤差の二乗の平均,1,1,2025-08-01,2025-08-01
3,MSE,誤差の二乗の平均,1,1,2025-08-01,2025-08-01
3,二乗平均平方根誤差,誤差の二乗の平均の平方根,1,1,2025-08-01,2025-08-01
3,RMSE,誤差の二乗の平均の平方根,1,1,2025-08-01,2025-08-01
3,平均絶対値誤差,誤差の絶対値の平均,1,1,2025-08-01,2025-08-01
3,MAE,誤差の絶対値の平均,1,1,2025-08-01,2025-08-01
3,偽陽性,予測値が陽性、実測値が陰性,1,1,2025-08-01,2025-08-01
3,正解率,予測における正解数をデータ数で割った値,1,1,2025-08-01,2025-08-01
3,過学習,訓練データに適合しすぎること。応用？融通？がきかない,1,1,2025-08-01,2025-08-01
3,過剰適合,過学習と一緒,1,1,2025-08-01,2025-08-01
3,NVIDIA,半導体企業、GPUの開発と製造、AI処理の効率化のために特化して設計された半導体,1,1,2025-08-01,2025-08-01
3,二乗和誤差,回帰問題（数値の予測）における損失係数。誤差を二乗して足しただけ。SSE,1,1,2025-08-01,2025-08-01
3,交差エントロピー誤差,分類問題における損失係数。実測値の対数と期待値の乗算を全部合わせたやつ,1,1,2025-08-01,2025-08-01
3,L1正則化,ラッソ回帰のこと,1,1,2025-08-01,2025-08-01
3,L2正則化,リッジ回帰のこと,1,1,2025-08-01,2025-08-01
3,L0正則化,モデルのパラメータの多くを完全に0にする（パラメータを減らす）ことで過学習を防ぐ。組み合わせ爆発して最適化が難しい,1,1,2025-08-01,2025-08-01
3,ElasticNet,リッジ回帰とラッソ回帰をかけ合わせた正則化の手法。,1,1,2025-08-01,2025-08-01
3,勾配降下法,その点の勾配を偏微分で調べて、損失係数が最小になるよう重みを更新する,1,1,2025-08-01,2025-08-01
3,バッチ勾配降下法,全部の訓練データで計算して重みを一回更新する。効率悪い。,1,1,2025-08-01,2025-08-01
3,最急降下法,勾配降下法と同じ意味,1,1,2025-08-01,2025-08-01
3,確率的勾配降下法,ランダムに訓練データ抽出して重みの更新をするのを繰り返す,1,1,2025-08-01,2025-08-01
3,オンライン学習,確率的勾配降下法を用いて1個ずつ微分する学習。インターネットに接続して、新しいデータを使う,1,1,2025-08-01,2025-08-01
3,エポック,ミニバッチ勾配降下法で抽出と微分を何回繰り返すか,1,1,2025-08-01,2025-08-01
3,ミニバッチ勾配降下法,ランダムにいくつか訓練データを抽出して、まとめて勾配を計算して重みを更新するのを繰り返す,1,1,2025-08-01,2025-08-01
3,局所最適解,全体で見たら最適ではないけど狭い範囲で見ると最適に見える,1,1,2025-08-01,2025-08-01
3,大域最適解,全体で見た最適,1,1,2025-08-01,2025-08-01
3,鞍点,馬の鞍のど真ん中あたりのこと。勾配がゼロになる,1,1,2025-08-01,2025-08-01
3,OpenPose,画像や動画から人の姿勢（ポーズ）をリアルタイムに検出できるライブラリ,1,1,2025-08-01,2025-08-01
3,Adam,MomentumとAdagradの合体版,1,1,2025-08-01,2025-08-01
3,グリッドサーチ,パラメータチューニングの手法で、最適な組み合わせを全通り試して導き出す,1,1,2025-08-01,2025-08-01
3,勾配消失問題,シグモイド関数やtanh関数は隅っこが勾配小さいから、層が厚くなると掛け算でほぼ0になる,1,1,2025-08-01,2025-08-01
3,tanh関数,ー１〜１のS字曲線,1,1,2025-08-01,2025-08-01
3,LeakyReLU関数,入力値が0より下の場合には1未満の数を乗算するReLU関数。ちょっと漏れるイメージ,1,1,2025-08-01,2025-08-01
3,ParametricReLU,入力値が0より下の場合にはパラーメータによって変動する1未満の数を乗算するReLU関数,1,1,2025-08-01,2025-08-01
3,RandomizedReLU,入力値が0より下の場合にはランダムな1未満の数を乗算するReLU関数,1,1,2025-08-01,2025-08-01
3,LeNet,初代のCNN。,1,1,2025-08-01,2025-08-01
3,オートエンコーダ,次元を圧縮してもとに戻す。ノイズを除去したり異常値を検出したりできる。,1,1,2025-08-01,2025-08-01
3,AlexNet,ISLVRC-2012で優勝したCNN。ReLUの導入,1,1,2025-08-01,2025-08-01
3,OpenAI Five,OpenAIによって開発された、複雑なゲームをプレイ可能なコンピュータプログラム,1,1,2025-08-01,2025-08-01
3,AlphaStar,制限なしでeスポーツ「StarCraft II」のトップリーグの実力に到達した最初のAI,1,1,2025-08-01,2025-08-01
3,枝刈り,決定木の過剰適合を防ぐため、一度木を構築してから情報の少ないノードを削除する,1,1,2025-08-01,2025-08-01
4,ロジック・セオリスト,1956年、初期の人工知能プログラム、ヒューリスティック探索を導入、計算機を超える,0,0,,
4,ローブナーコンテスト,特にチューリングテストに基づいたAIの会話能力を競う大会,0,0,,
4,STRIPS,AIが目的を達成するために必要な手順を、前提条件、行動、結果の３つで分けて計画すること,0,0,,
4,SHRDLU,1968年〜1970年、仮想の世界で積み木の操作や質問応答ができるシステム,0,0,,
4,Cycプロジェクト,1984年〜現在、一般常識をデータベース化するプロジェクト,1,0,2025-08-01,
4,ヒューリスティックな知識,経験や直感、過去の成功例などを基に正解に最も近い答えを迅速に導き出すための知識,0,0,,
4,Mini-Max法,ゲーム木を探索、評価関数の値によって手を決定。深さ優先で全探索,0,0,,
4,αβ法,ゲーム木を探索、評価関数の値によって手を決定。不必要なノードの探索をカット,0,0,,
4,DENDRAL,1960年代、エキスパートシステムの一種。未知の有機化合物の分析、特定,0,0,,
4,オントロジー,特定の文字列がどういうモノ、コトなのかを機械が分かるように整理すること,0,0,,
4,ライトウェイト・オントロジー,AIが自分で情報間の関係性を見つけるというアプローチ,0,0,,
4,ヘビーウェイト・オントロジー,人間が持つ知識の概念を正しくAIに教えようとするアプローチ,0,0,,
4,レコメンデーションエンジン,顧客の好みを予測し、商品をすすめるのに使われる,0,0,,
4,特徴表現学習,機械が自らデータから自動的に重要な特徴を抽出して学習する方法,0,0,,
4,強化学習,,0,0,,
4,マージン最大化,SVMで分類の境界とデータポイント間の距離を最大化する考え方,1,0,2025-08-01,
4,閾値,,0,0,,
4,自己回帰モデル,前のデータが後のデータに影響を与えるという仮定に基づき、その影響の大きさを係数で表現,0,0,,
4,ARモデル,自己回帰モデル。現在の値を過去のデータを用いて回帰する時系列モデル,0,0,,
4,ベクトル自己回帰モデル,単変量自己回帰モデル（ARモデル）を複数の変数に拡張,0,0,,
4,ウォード法,階層型クラスタリングの手法の一つ。クラスタ内の分散を最小化するようにデータをグループ分けしていく手法,0,0,,
4,最短距離法,2つのクラスタ間で一番近いデータ同士の距離を、クラスタ間の距離として採用する手法,1,0,2025-08-01,
4,特異値分解,次元削減手法のひとつ。任意の行列を3つの行列の積に分解、重要度の低い列ベクトルを削ることで次元を下げる,0,0,,
4,SVD,特異値分解のこと。,0,0,,
4,多次元尺度構成法,類似度を元に対象の関係を視覚的に分かりやすい形に変換する分析手法。散布図で表す。,0,0,,
4,MDS,多次元尺度構成法のこと。,0,0,,
4,協調フィルタリング,,0,0,,
4,レコメンデーション,,0,0,,
4,コールドスタート問題,,0,0,,
4,コンテンツベースフィルタリング,,0,0,,
4,トピックモデル,,0,0,,
4,潜在的ディリクレ配分法,,0,0,,
4,t-SNE,次元削減の手法のひとつ。高次元で近接しているデータ点が低次元でも近接するようにマッピングすること。目的は可視化,1,0,2025-08-01,
4,エージェント,,0,0,,
4,割引率,,0,0,,
4,バンディットアルゴリズム,,0,0,,
4,活用,,0,0,,
4,探索,,0,0,,
4,e-greedy方策,,0,0,,
4,UCB方策,,0,0,,
4,方策,,0,0,,
4,マルコフ決定過程モデル,,0,0,,
4,マルコフ性,,0,0,,
4,マルコフ決定過程,,0,0,,
4,価値関数,,0,0,,
4,状態価値関数,,0,0,,
4,行動価値関数,,0,0,,
4,Q値,,0,0,,
4,Q学習,,0,0,,
4,SARSA,,0,0,,
4,方策勾配法,,0,0,,
4,REINFORCE,,0,0,,
4,Actor-Critic,,0,0,,
4,LDA,潜在的ディリクレ配分法のこと,0,0,,
4,ホールドアウト検証,訓練データとテストデータに1回だけ分割して評価する手法,0,1,,2025-08-01
4,予測誤差,モデルが予測した値と、実際の正解（観測値）との差。損失係数とかにする前のそのままのやつ,1,0,2025-08-01,
4,適合率,予測値が陽性のデータ全体のうち、実測も陽性だった割合,1,0,2025-08-01,
4,再現率,実測値が陽性のデータ全体のうち、予測も陽性だった割合,1,0,2025-08-01,
4,F値,適合率と再現率を元に出したモデルの精度。正解率だけだと偏りのあるデータセットで正確な精度が出せないので。,1,0,2025-08-07,
4,混同行列,論理式の実測値と予測値、2×2の行列,1,0,2025-08-01,
4,ROC曲線,「真陽性率（TPR）」と「偽陽性率（FPR）」の関係を可視化したもの。,1,0,2025-08-01,
4,AUC,ROC曲線の下の面積,1,1,2025-08-01,2025-08-07
4,オッカムの剃刀,モデルの選択・設計のとき、過学習のリスクを避けるためにも「シンプルな方」を選ぶべき,0,0,,
4,情報量基準,統計モデルや機械学習モデルの良さを比較するための指標。AICやBICが有名,0,0,,
4,赤池情報量規準,柔軟にモデル選びしたいときに使う式。過学習気味のモデルも含めて見たい。,0,0,,
4,AIC,赤池情報量規準のこと,1,1,2025-08-01,2025-08-07
4,ベイズ情報量基準,慎重にモデルを選びたいときに使う式。シンプルで本質的な構造を優先。,0,0,,
4,BIC,ベイズ情報量基準のこと,1,1,2025-08-01,2025-08-07
4,ムーアの法則,半導体の集積密度が約18ヶ月（あるいは2年）ごとに2倍になるという経験則,0,0,,
4,TPU,Googleが開発した機械学習用プロセッサ,0,0,,
4,バーニーおじさんのルール,機械学習において、必要なデータの量はモデルのパラメータの十倍だという経験則,0,0,,
4,距離学習,,0,0,,
4,SiameseNetwork,,0,0,,
4,TripletNetwork,,0,0,,
4,ContrasiveLoss,,0,0,,
4,TripletLoss,,0,0,,
4,カルバック・ライブラー情報量,,0,0,,
4,イェンゼン・シャノン情報量,,0,0,,
4,変分オートエンコーダ,,0,0,,
4,VAE,変分オートエンコーダのこと,1,1,2025-08-01,2025-08-07
4,Adagrad,損失関数の最小に近づくにつれ、学習率を低下させることでSGDより効率的に最適化できる,1,0,2025-08-01,
4,RMSprop,,0,0,,
4,AdaBound,,0,0,,
4,AMSBound,,0,0,,
4,早期終了,,0,0,,
4,ノーフリーランチ定数,,0,0,,
4,二重降下現象,,0,0,,
4,ランダムサーチ,,0,0,,
4,Adadelta,学習率が最終的に0になってしまわないように改良された、最適化の手法,0,0,,
4,信用割当問題,,0,0,,
4,勾配爆発問題,,0,0,,
4,AtrousConvolution,,0,0,,
4,DiatedConvolution,,0,0,,
4,DepthwiseSeparableConvolution,,0,0,,
4,DepthwiseConvolution,,0,0,,
4,PointwiseConvolution,,0,0,,
4,ダウンサンプリング,,0,0,,
4,サブサンプリング,,0,0,,
4,連鎖律,合成関数を微分するとき、その導関数がそれぞれの導関数の積で与えられる,1,0,2025-08-01,
4,GlobalAveragePooling,,0,0,,
4,スキップ結合,,0,0,,
4,バッチ正規化,,0,0,,
4,レイヤー正規化,,0,0,,
4,インスタンス正規化,,0,0,,
4,グループ正規化,,0,0,,
4,回帰結合層,,0,0,,
4,RNN,入力が順番のあるデータで、過去の入力情報を“記憶”しながら処理していく再帰型NN。自然言語処理（NLP）に使われる,0,0,,
4,PretrainedModels,,0,0,,
4,エルマンネットワーク,,0,0,,
4,ジョルダンネットワーク,,0,0,,
4,LSTM,,0,0,,
4,入力重み衝突,,0,0,,
4,出力重み衝突,,0,0,,
4,CEC,,0,0,,
4,GRU,,0,0,,
4,LSTMブロック,,0,0,,
4,BidirectionalRNN,,0,0,,
4,Seq2Seq,,0,0,,
4,RNN エンコーダ-デコーダ,,0,0,,
4,ImageCaptioning,,0,0,,
4,BPTT,,0,0,,
4,教師強制,,0,0,,
4,Attention,,0,0,,
4,Source-Target Attention,,0,0,,
4,Encoder-Decodeer Attention,,0,0,,
4,Self-Attention,,0,0,,
4,位置エンコーディング,,0,0,,
4,Multi-Head Attention,,0,0,,
4,積層オートエンコーダ,,0,0,,
4,事前学習,,0,0,,
4,変分オートエンコーダ,,0,0,,
4,ネオコグニトロン,,0,0,,
4,全結合層,層内のすべてのニューロンが前の層のすべてのニューロンと接続されている層。Affine層。,1,0,2025-08-01,
4,VGG,,0,0,,
4,GoogLeNet,ISLVRC-2014で優勝したCNN。各畳み込み層を計算効率の良い Inceptionブロックで近似・代替,1,0,2025-08-01,
4,Inceptionモジュール,,0,0,,
4,ResNet,ISLVRC-2015で優勝したCNN。深いネットでも学習が進むように skip connection（残差接続）を入れたモデル,0,0,,
4,WideResNet,,0,0,,
4,DenseNet,,0,0,,
4,Squeeze-and-Excitation Networks,,0,0,,
4,MobileNet,,0,0,,
4,NeuralArchitectureSearch,,0,0,,
4,NAS,,0,0,,
4,NASNet,,0,0,,
4,MnasNet,,0,0,,
4,EfficientNet,画像認識。精度と軽さのバランスが良い最先端モデル,0,0,,
4,R-CNN,Selective Searchと呼ばれる物体候補アルゴリズムを使用する物体検出アルゴリズム,0,0,,
4,FPN,画像から抽出された特徴をピラミッド型に伝播させる手法。小さいものも大きいものも検出できる。解像度と特徴,0,0,,
4,YOLO,物体検出。画像をグリッドに分けて、一気にバウンディングボックス＋クラス予測。速い,1,0,2025-08-01,
4,SSD,物体検出。マルチスケール特徴マップでアスペクト比ごとに識別。速い,0,0,,
4,Fast R-CNN,物体検出。画像全体にCNNかけて、領域ごとの特徴を切り出す → 速くなった,1,0,2025-08-01,
4,Faster R-CNN,物体検出。領域提案も学習で行う（RPN） → 精度と速度のバランス◎,1,0,2025-08-01,
4,デフォルトボックス,,0,0,,
4,セグメンテーションタスク,,0,0,,
4,セマンティックセグメンテーション,ピクセルごとに「これはネコ」「これは背景」みたいに分類。,0,0,,
4,インスタンスセグメンテーション,ピクセルごとの分類＋個体ごとの分離。,0,0,,
4,パノプティックセグメンテーション,,0,0,,
4,FCN,,0,0,,
4,SegNet,,0,0,,
4,PyramidPoolingModule,,0,0,,
4,PSPNet,,0,0,,
4,DeepLab,,0,0,,
4,ConvolutionalPoseMachines,,0,0,,
4,FullyConvolutionalNetwork,FPNのこと,0,0,,
4,PartsAffinityFields,,0,0,,
4,Mask R-CNN,,0,0,,
4,A-D変換,,0,0,,
4,PCM,,0,0,,
4,パルス符号変調,,0,0,,
4,高速フーリエ変換,連続的なデータの周波数成分への変換を高速化できる手法のひとつ,1,0,2025-08-01,
4,FFT,,0,0,,
4,周波数スペクトル,,0,0,,
4,スペクトル包絡,,0,0,,
4,メル周波数ケプストラム係数,,0,0,,
4,MFCC,,0,0,,
4,フォルマント,,0,0,,
4,Speech-to-Text,,0,0,,
4,HiddenMarkovModel,,0,0,,
4,GaussionMixtureModel,,0,0,,
4,ConnectionistTemporalClassification,,0,0,,
4,WaveNet,,0,0,,
4,n-gram,,0,0,,
4,Bag-of-Words,,0,0,,
4,BoW,Bag-of-Wordsのこと,1,1,2025-08-07,2025-08-07
4,Bag-of-n-grams,,0,0,,
4,ワンホットベクトル,,0,0,,
4,TF-IDF,,0,0,,
4,局所表現,,0,0,,
4,単語埋め込み,,0,0,,
4,分散表現,,0,0,,
4,word2vec,,0,0,,
4,分布仮説,,0,0,,
4,スキップグラム,,0,0,,
4,CBOW,,0,0,,
4,fastText,Facebookが公開した自然言語処理ライブラリ,0,0,,
4,ELMo,,0,0,,
4,事前学習,,0,0,,
4,転移学習,,0,0,,
4,BERT,,0,0,,
4,自然言語推論,,0,0,,
4,質問応答,,0,0,,
4,意味的類似度,,0,0,,
4,文書分類,,0,0,,
4,評判分析,,0,0,,
4,言語理解タスク,,0,0,,
4,GeneralLnguageUnderstandingEvaluation,,0,0,,
4,MaskedLanguageModel,,0,0,,
4,NextSentencePrediction,,0,0,,
4,品詞タグ付け,,0,0,,
4,固有表現解析,,0,0,,
4,SQuAD,,0,0,,
4,ALBERT,,0,0,,
4,DistilBERT,,0,0,,
4,Megatron-LM,,0,0,,
4,Turning-NLG,,0,0,,
4,VisionTransformer,,0,0,,
4,RLHF,,0,0,,
4,PaLM,,0,0,,
4,Chinchilla,,0,0,,
4,PanGu-∑,,0,0,,
4,GLUE,,0,0,,
4,感情分析,,0,0,,
4,深層強化学習,,0,0,,
4,DQN,,0,0,,
4,経験再生,,0,0,,
4,ターゲットネットワーク,,0,0,,
4,優先度付き経験再生,,0,0,,
4,デュエリングネットワーク,,0,0,,
4,ノイジーネットワーク,,0,0,,
4,カテゴリカルDQN,,0,0,,
4,Rainbow,,0,0,,
4,内発的報酬,,0,0,,
4,マルチエージェント強化学習,,0,0,,
4,状態表現学習,,0,0,,
4,連続値制御,,0,0,,
4,報酬成形,,0,0,,
4,ドメイン知識,,0,0,,
4,オフラインデータ,,0,0,,
4,模倣学習,,0,0,,
4,sim2real,,0,0,,
4,ドメインランダマイゼーション,,0,0,,
4,残差強化学習,,0,0,,
4,モデルベース強化学習,,0,0,,
4,モデルフリー,,0,0,,
4,世界モデル,,0,0,,
4,潜在空間,,0,0,,
4,敵対的生成ネットワーク,,0,0,,
4,ディスクリミネータ,,0,0,,
4,ジェネレータ,,0,0,,
4,GAN,,0,0,,
4,DCGAN,,0,0,,
4,Pix2Pix,,0,0,,
4,CycleGAN,,0,0,,
4,DiffusionModel,,0,0,,
4,拡散過程,,0,0,,
4,逆拡散過程,,0,0,,
4,NeRF,,0,0,,
4,転移学習,,0,0,,
4,ファインチューニング,,0,0,,
4,Few=shot学習,,0,0,,
4,MAML,,0,0,,
4,メタ学習,,0,0,,
4,One-shot学習,,0,0,,
4,Zero-shot学習,,0,0,,
4,半教師あり学習,,0,0,,
4,一致正正則化,,0,0,,
4,Consistency regularization,,0,0,,
4,FixMatch,,0,0,,
4,自己教師あり学習,,0,0,,
4,プレテキストタスク,,0,0,,
4,継続学習,,0,0,,
4,破滅的忘却,,0,0,,
4,ImageCaptioning,,0,0,,
4,マルチモーダルタスク,,0,0,,
4,CLIP,,0,0,,
4,DALL-E,,0,0,,
4,Flamingo,,0,0,,
4,Unified-IO,,0,0,,
4,基盤モデル,,0,0,,
4,説明可能AI,,0,0,,
4,PermutationImportance,,0,0,,
4,CAM,,0,0,,
4,GAP,,0,0,,
4,Grad-CAM,,0,0,,
4,GuidedGrad-CAM,,0,0,,
4,蒸留,,0,0,,
4,教師ネットワーク,,0,0,,
4,生徒ネットワーク,,0,0,,
4,hard target,,0,0,,
4,soft target,,0,0,,
4,マグニチュードベース,,0,0,,
4,勾配ベース,,0,0,,
4,宝くじ仮説,,0,0,,
4,量子化,,0,0,,
